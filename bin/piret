#!/usr/bin/env python

"""
RNA seq pipeline.

wrapper for running RNASeq pipeline

"""

import os
import sys
import argparse
import logging
dir_path = os.path.dirname(os.path.realpath(__file__))
lib_path = os.path.abspath(os.path.join(dir_path, '..'))
bin_path = os.path.join(lib_path, 'bin')
script_path = os.path.join(lib_path, 'scripts')
sys.path.append(lib_path)
sys.path.append(script_path)
os.environ["PATH"] += os.pathsep + bin_path
os.environ["PATH"] += os.pathsep + script_path
from piret.checks import CheckDesign, CheckDependencies
from piret.checks.dependencies import check_depen, check_pydepen
from piret.workflows import DualSeq, SingleSeq
from piret.checks.gff3 import CheckGFF
from piret.checks.aligner import check_aligner
from piret.checks.config import parse_config, check_input
from piret.logger import create_logger
from piret.pathways import opaver
from luigi.interface import build


def cmdline_parser():
    """
    Create an argparse instance.

    Combination of different options for this script.
    """
    class CustomFormatter(argparse.ArgumentDefaultsHelpFormatter,
                          argparse.RawDescriptionHelpFormatter):
        """For multiple formatters of argparse."""

        pass

    parser = argparse.ArgumentParser(formatter_class=CustomFormatter,
                                     prog='piret',
                                     description="""piret""",
                                     epilog="""
Example runs:\n
        piret -d <workdir> -e <design file>  -c <config file>
        """)

    required_args = parser.add_argument_group()

    required_args.add_argument("-d", dest="WORKDIR", help="""working directory where all
        output files will be processed and written""")

    required_args.add_argument("-e", dest="EXPDSN", help="""tab delimited experimental
        design file""", default=argparse.SUPPRESS)

    required_args.add_argument("-c", "--config", help="""luigi config file for setting
        parameters that control each step, see github repo for an example""", default=None)

    parser.add_argument('-v', '--version', action='version', version='%(prog)s 0.3.4')
    # A delete command
    check_args = parser.add_mutually_exclusive_group(required=False)
    check_args.add_argument('--check', help="""Check if all dependencies are
                                        installed and in path""",
                        action='store_true')

    return parser


def main():
    """
    Main function.

    All functions are called here.
    """
    parser = cmdline_parser()
    args = parser.parse_args()

    if args.check is True:
        depen_list = ["samtools", "bamtools", "R", "featurecounts",
                     "hisat2", "star", "faqcs", "stringtie",
                     "bedtools", "diamond"]
        depen_list.sort()
        check_depen(depen_list)
        check_pydepen()
        sys.exit()

    #TODO: figure out why this is not working
    os.environ["LUIGI_CONFIG_PATH"] = args.config

    # setting up logging files
    logger = create_logger(args.WORKDIR)

    # get parameters from the config file
    paras = parse_config(args.config)

    # check if correct options are selected
    check_input(paras, parser=parser)

    # getting absolute path of workdir
    workdir = os.path.abspath(args.WORKDIR)

    if check_exp_design(args.EXPDSN) is False:  # check if experimental design file is OK
        sys.exit("Your experimental design file has formatting problems!")

    # convert exerimental design file to a dictionary object
    samp_dic = CheckDesign(args.EXPDSN).extract_sample_fastqs()

    no_of_jobs = 1

    # assigns filenames for databases if not specified.
    db = check_aligner(aligner=paras["aligner"],
                       hisat_index=paras["hisat_index"],
                       workdir=workdir, star_db=paras["star_index"])

    # TODO move this to log file
    summarize_run(aligner=paras["aligner"])  # print run information in screen

    # assign universal fasta and gff variable
    if paras["kingdom"] in ["prokarya", "eukarya"]:
        if paras["kingdom"] == "prokarya":
            fasta = paras["fasta_prok"]
            gff = paras["gff_prok"]
        elif paras["kingdom"] == "eukarya":
            fasta = paras["fasta_euk"]
            gff = paras["gff_euk"]
        single_seq = SingleSeq(qc=paras["qc"],
                               fastq_dic=samp_dic,
                               aligner=paras["aligner"],
                               ref_fasta=fasta,
                               num_cpus=paras["threads"],
                               local_scheduler=True,
                               hisat_index=db,
                               workdir=workdir,
                               kingdom=paras["kingdom"],
                               no_of_jobs=no_of_jobs,
                               p_value=paras["q_value"],
                               exp_desn_file=args.EXPDSN,
                               stardb_dir=db,
                               emap_dir=paras["emap_db"],
                               gff_file=gff,
                               pathway=paras["pathway"])

        # step 1, run qc
        qc_dic = single_seq.run_faqc()

        # step 2, create database, hisat2 or stardb
        single_seq.create_db()

        # step 3, map reads, hisat2 or stardb
        single_seq.map_reads(qc_dic=qc_dic)

        # step 4, summarize the mapped reads
        single_seq.map_summarize()

        # step 5, if needed
        if paras["novel"] is True:  # if novel regions are to be reported
            single_seq.extract_pp()  # extract properly paired reads
            single_seq.NovelRegions()  # find novel regions
            single_seq.create_new_gff()  # create a new GFF file that has novel region info
            gff = os.path.join(workdir, "processes", "novel", "updated.gff")  # update gff
        # step 6, run read counts
        single_seq.feature_count(new_gff=gff)
        single_seq.merge_stringtie(new_gff=gff)

        # find diff expressed gene using edgeR
        if "edgeR" in paras["method"]:
            single_seq.run_edger()
        # use DESeq2
        if "DESeq2" in paras["method"]:
            single_seq.run_deseq2()
        if "ballgown" in paras["method"]:
            single_seq.restringtie()
            single_seq.run_ballgown()

        # run opaver pathway analysis
        if paras["pathway"] is True:
            # run emapper
            single_seq.run_emapper(new_gff=gff)
            if "edgeR" in paras["method"]:
                single_seq.run_opaver(method="edgeR")
            if "DESeq2" in paras["method"]:
                single_seq.run_opaver(method="DESeq2")

        # summarize all results into one big json file.
        single_seq.summ_json(new_gff=gff, method=paras["method"],
                             NovelRegions=paras["novel"])

    elif paras["kingdom"] == "both":
        euk_fasta = paras["fasta_euk"]
        euk_gff = paras["gff_euk"]
        prok_fasta = paras["fasta_prok"]
        prok_gff = paras["gff_prok"]

        dual_seq = DualSeq(qc=paras["qc"],
                           fastq_dic=samp_dic, 
                           kingdom=paras["kingdom"],
                           aligner=paras["aligner"],
                           euk_fasta=paras["fasta_euk"],
                           prok_fasta=paras["fasta_prok"],
                           prok_gff=paras["gff_prok"],
                           euk_gff=paras["gff_euk"],
                           workdir=workdir,
                           p_value=paras["q_value"],
                           exp_desn_file=args.EXPDSN,
                           hisat_index=db,
                           local_scheduler=True,
                           pathway=paras["pathway"],
                           num_cpus=paras["threads"],
                           stardb_dir = paras["star_index"],
                           emap_dir=paras["emap_db"])

        # step 1, run qc
        qc_dic = dual_seq.run_faqc()
        
        # step 2, create database, hisat2 or stardb
        dual_seq.create_db()

        # step 3, map reads, hisat2 or stardb
        dual_seq.map_reads()

        # step 4, summarize the mapped reads
        dual_seq.map_summarize()
        dual_seq.split_prokeuk()

        # step 5, if needed
        if paras["novel"] is True:  # if novel regions are to be reported
            dual_seq.extract_pp()  # extract properly paired reads
            dual_seq.NovelRegions()  # find novel regions
            dual_seq.create_new_gff()  # create a new GFF file that has novel region info
            euk_gff = os.path.join(workdir,
                                   "processes", "novel",
                                   "euk_updated.gff")  # update gff
            prok_gff = os.path.join(workdir, "processes", "novel",
                                    "prok_updated.gff")  # update gff
    
        # step 6, run read counts
        print("Counting eukaryotes")
        dual_seq.feature_counts(new_gff=euk_gff, kingdom="eukarya")
        dual_seq.feature_counts(new_gff=prok_gff, kingdom="prokarya")
        dual_seq.merge_stringtie(new_gff=prok_gff + "," + euk_gff)

        # find diff expressed gene using edgeR
        if "edgeR" in paras["method"]:
            dual_seq.run_edger(kingdom="eukarya")
            dual_seq.run_edger(kingdom="prokarya")
        if "DESeq2" in paras["method"]:
            dual_seq.run_deseq2(kingdom="eukarya")
            dual_seq.run_deseq2(kingdom="prokarya")
        if "ballgown" in paras["method"]:
            dual_seq.restringtie()
            dual_seq.run_ballgown()

        if paras["pathway"] is True:
            # run emapper
            dual_seq.run_emapper(new_gff=prok_gff, kingdom="prokarya", fasta=prok_fasta)
            dual_seq.run_emapper(new_gff=euk_gff, kingdom="eukarya", fasta=euk_fasta)
            if "edgeR" in paras["method"]:
                dual_seq.run_opaver(method="edgeR", kingdom="prokarya")
                dual_seq.run_opaver(method="edgeR", kingdom="eukarya")
            if "DESeq2" in paras["method"]:
                dual_seq.run_opaver(method="DESeq2", kingdom="prokarya")
                dual_seq.run_opaver(method="DESeq2", kingdom="eukarya")

        # summarize all results into one big json file.
        dual_seq.summ_json(new_gff=euk_gff, method=paras["method"],
                           NovelRegions=paras["novel"],
                           kingdom="eukarya",
                           fasta=euk_fasta)
        dual_seq.summ_json(new_gff=euk_gff, method=paras["method"],
                           NovelRegions=paras["novel"],
                           kingdom="prokarya",
                           fasta=prok_fasta)


def check_exp_design(exp_design_file):
    """A function that checks different aspects of experimental des. file.

    it returns True if all checked conditions are True. This is the first step
    of the pipeline.
    """
    exp_desn = CheckDesign(exp_design_file)
    if all([exp_desn.tab(),
            exp_desn.header(),
            exp_desn.sample_name(),
            exp_desn.file_name(),
            exp_desn.group_name(),
            exp_desn.sample_name(),
            exp_desn.fastq_exists()]) is True:
        return True


def check_gff(gff_file):
    """A function that checks gff file.

    it returns True if all checked conditions are True. This is one of
    the first stepof the pipeline.
    """
    gff = CheckGFF(gff_file)
    if all([gff.size(), gff.check_id(), gff.check_unique_id()]) is True:
        return True
    else:
        return False

def summarize_run(aligner):
    """Prints summary information of runs."""
    print("Alignment will be done using: %s" %aligner)


if __name__ == '__main__':
    main()
